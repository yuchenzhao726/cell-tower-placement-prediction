spark-shell --deploy-mode client --packages "org.locationtech.geotrellis:geotrellis-spark_2.12:3.1.0"

import org.apache.spark.sql.Row
import org.apache.spark.sql.types._
import org.apache.hadoop.fs.Path
import geotrellis.spark.store.hadoop.HadoopGeoTiffRDD
import geotrellis.raster._
import geotrellis.vector.Extent

val inputTiff = new Path("/user/gw2310_nyu_edu/bdad_proj/population.tif")
val inputDataDir = "/user/gw2310_nyu_edu/bdad_proj/training_set_1" 
val outputDir = "/user/gw2310_nyu_edu/bdad_proj/training_set_2"  

val geoTiffRDD = HadoopGeoTiffRDD.spatial(inputTiff)(sc)

// create a rectangle between (42 lat, -71 lon) and (33 lat, -125 lon)
val filterExtent = Extent(-125, 33, -71, 42) 

// filter in extent intersected with the rectangle
val filteredRDD = geoTiffRDD.filter { case (key, tile) =>
  filterExtent.intersects(key.extent)
}

val records = filteredRDD.flatMap { case (key, tile) =>
  val rasterExtent = RasterExtent(key.extent, tile.cols, tile.rows)
  for {
    col <- 0 until tile.cols
    row <- 0 until tile.rows
    pop_den = tile.getDouble(col, row)
    if !pop_den.isNaN
  } yield {
    val latlon = rasterExtent.gridToMap(col, row) 
    Row(latlon._1, latlon._2, pop_den)
  }
}

// normalize data between 0 and 1 by x-min/max-min
val maxPopDen = records.map(row => row.getDouble(2)).max()
val normalizedRecords = records.map(row => {
  Row(row.getDouble(0), row.getDouble(1), row.getDouble(2) / maxPopDen)
})

// create popDen dataframe
val schema = StructType(
  List(
    StructField("lon", DoubleType, false),
    StructField("lat", DoubleType, false),
    StructField("pop_den", DoubleType, false)
  )
)

val df1 = spark.createDataFrame(normalizedRecords, schema)
df1.createOrReplaceTempView("pop_table")

// join pop_den into random_places
val df2 = spark.read.parquet(inputDataDir)
df2.createOrReplaceTempView("random_places")

val result = spark.sql("""SELECT random_places.*, AVG(pop_table.pop_den) AS pop_den 
                    FROM random_places 
                    LEFT JOIN pop_table ON pop_table.lon > random_places.lon1 AND pop_table.lon < random_places.lon2 AND pop_table.lat > random_places.lat1 AND pop_table.lat < random_places.lat2 
                    GROUP BY random_places.lon1, random_places.lat1, random_places.lon2, random_places.lat2, random_places.area, random_places.cell_tower_num
""") 

result.write.parquet(outputDir)




